{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './data/'\n",
    "data_config = pickle.load(open(base_dir + 'data_config.dict', 'rb'))\n",
    "MAX_LEN = data_config['MAX_LEN']\n",
    "WORD_DIM = data_config['WORD_DIM']\n",
    "RELATION_NUM = data_config['RELATION_NUM']\n",
    "POS_MIN = -100\n",
    "POS_EMBED_LEN = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22549, 300) 22548\n"
     ]
    }
   ],
   "source": [
    "word_embed = pickle.load(open(base_dir + 'word_embed', 'rb'))\n",
    "word_embed = np.transpose(word_embed)\n",
    "PAD_ID = word_embed.shape[0]-1\n",
    "print(word_embed.shape, PAD_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2lb = pickle.load(open(base_dir + 'rel2lb.dict', 'rb'))\n",
    "OTHER_LABEL = rel2lb['Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from tfrecord\n",
    "\n",
    "def pad_fixed_length(words):\n",
    "    words = tf.pad(words,tf.constant([[0, MAX_LEN-words.shape[0]]]), constant_values=PAD_ID)\n",
    "    return words\n",
    "\n",
    "def processing(raw):\n",
    "    features = tf.io.parse_single_example(\n",
    "        raw,\n",
    "        features={\n",
    "            'idxs': tf.io.FixedLenFeature([2], tf.int64),\n",
    "            'label': tf.io.FixedLenFeature([1], tf.int64),\n",
    "            'words': tf.io.VarLenFeature(tf.int64)\n",
    "        }\n",
    "    )\n",
    "    idxs = tf.cast(features['idxs'], tf.int32)\n",
    "    pos1 = tf.range(0, MAX_LEN, 1, dtype=tf.int32) - idxs[0]\n",
    "    pos2 = tf.range(0, MAX_LEN, 1, dtype=tf.int32) - idxs[1]\n",
    "    pos1 = pos1 - POS_MIN\n",
    "    pos2 = pos2 - POS_MIN\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    words = tf.cast(tf.sparse.to_dense(features['words']), tf.int32)\n",
    "    words = tf.py_function(pad_fixed_length, [words], Tout=tf.int32)\n",
    "    return pos1, pos2, label, words\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(filenames = [base_dir + 'train.tfrecords']).map(processing).shuffle(2000).batch(128)\n",
    "test_ds = tf.data.TFRecordDataset(filenames = [base_dir + 'test.tfrecords']).map(processing).shuffle(2000).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(keras.Model):\n",
    "    def __init__(self, word_embed, pos_dim, word_dim, class_num, class_dim, other_label, hyperparams):\n",
    "        super(Network, self).__init__()\n",
    "        self.pos_dim = pos_dim\n",
    "        self.word_dim = word_dim\n",
    "        self.other_label = tf.constant(other_label, dtype=tf.int32)\n",
    "        self.m_neg = tf.constant(hyperparams['m_neg'])\n",
    "        self.m_pos = tf.constant(hyperparams['m_pos'])\n",
    "        self.gamma = tf.constant(hyperparams['gamma'])\n",
    "        self.beta = tf.constant(hyperparams['beta'])\n",
    "        self.word_embed = tf.Variable(word_embed, dtype=tf.float32)\n",
    "        self.pos1_embed = tf.Variable(tf.random.uniform([POS_EMBED_LEN, pos_dim],minval=0,maxval=1), dtype=tf.float32)\n",
    "        self.pos2_embed = tf.Variable(tf.random.uniform([POS_EMBED_LEN, pos_dim],minval=0,maxval=1), dtype=tf.float32)\n",
    "        class_embed_init_param = tf.sqrt(6/(class_num + class_dim))\n",
    "        self.class_matrix = tf.Variable(tf.random.uniform([class_dim, class_num],minval=-class_embed_init_param, maxval=class_embed_init_param), dtype=tf.float32) \n",
    "        \n",
    "        \n",
    "        ctx1 = np.zeros([MAX_LEN, MAX_LEN])\n",
    "        for i in range(0,MAX_LEN-1):\n",
    "            ctx1[i+1, i] = 1\n",
    "            \n",
    "        ctx2 = np.zeros([MAX_LEN, MAX_LEN])\n",
    "        for i in range(1,MAX_LEN):\n",
    "            ctx2[i-1, i] = 1\n",
    "        \n",
    "        self.ctx_mat1 = tf.constant(ctx1, dtype=tf.float32)\n",
    "        self.ctx_mat2 = tf.constant(ctx2, dtype=tf.float32)\n",
    "        \n",
    "        self.conv1 = layers.Conv1D(class_dim, 1, padding='same', activation=tf.nn.tanh)\n",
    "        self.pool1 = layers.MaxPool1D(MAX_LEN, padding='same')\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    @tf.function(experimental_relax_shapes=True)\n",
    "    def other_loss_func(score, m_neg, gamma):\n",
    "        return tf.math.log(1.0 + tf.exp(gamma*(m_neg + tf.reduce_max(score, axis=1))))\n",
    "    \n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def remove_ele(data):\n",
    "        label = tf.cast(data[-1], dtype=tf.int32)\n",
    "        row = data[:-1]\n",
    "        return tf.concat([row[:label],row[label+1:]], axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    @tf.function(experimental_relax_shapes=True)\n",
    "    def class_loss_func(score, class_label, m_neg, m_pos, gamma):\n",
    "        \n",
    "        first_term = tf.math.log(1.0 + tf.exp(gamma*(m_pos - tf.gather_nd(score, tf.expand_dims(class_label, axis=1), batch_dims=1 ))))\n",
    "        first_term = tf.squeeze(first_term, axis=1)\n",
    "        score_temp = tf.map_fn(Network.remove_ele, tf.concat([score, tf.cast(class_label, dtype=tf.float32)], axis=1), dtype=tf.float32)\n",
    "        second_term = tf.math.log(1.0 + tf.exp(gamma*(m_neg + tf.reduce_max(score_temp, axis=1))))\n",
    "        return first_term + second_term\n",
    "\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        pos1 = inputs[0]\n",
    "        pos2 = inputs[1]\n",
    "        label = inputs[2]\n",
    "        words = inputs[3]\n",
    "        pf1 = tf.nn.embedding_lookup(self.pos1_embed, pos1)\n",
    "        pf2 = tf.nn.embedding_lookup(self.pos2_embed, pos2)\n",
    "        wf = tf.nn.embedding_lookup(self.word_embed, words)\n",
    "        wf = tf.concat([pf1, pf2, wf], axis=2)\n",
    "        wf_before = tf.matmul(self.ctx_mat1, wf)\n",
    "        wf_follow = tf.matmul(self.ctx_mat2, wf)\n",
    "        wf_context = tf.concat([wf_before, wf, wf_follow], axis=2)\n",
    "        \n",
    "        x = self.conv1(wf_context)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = tf.matmul(x, self.class_matrix)\n",
    "        x = tf.squeeze(x, axis=1)\n",
    "        \n",
    "        if training:\n",
    "            other_mask = tf.squeeze(tf.equal(label, self.other_label), axis=1)\n",
    "            class_mask = tf.math.logical_not(other_mask)\n",
    "            other_scores = tf.boolean_mask(x, other_mask)\n",
    "            class_scores = tf.boolean_mask(x, class_mask)\n",
    "            class_label = tf.boolean_mask(label, class_mask)\n",
    "            loss1 = Network.other_loss_func(other_scores, self.m_neg, self.gamma)\n",
    "            loss2 = Network.class_loss_func(class_scores, class_label, self.m_neg, self.m_pos, self.gamma)\n",
    "            loss_sum = tf.reduce_sum(tf.concat([loss1,loss2], axis=0))\n",
    "            theta_loss = tf.keras.regularizers.l2(self.beta)(self.word_embed) + tf.keras.regularizers.l2(self.beta)(self.pos1_embed) + tf.keras.regularizers.l2(self.beta)(self.pos2_embed)\\\n",
    "                + tf.keras.regularizers.l2(self.beta)(self.class_matrix) + tf.keras.regularizers.l2(self.beta)(self.conv1.weights[0])\n",
    "            loss_sum = theta_loss + loss_sum\n",
    "            loss_avg = loss_sum / tf.cast(tf.shape(label)[0], tf.float32)\n",
    "            return x, loss_avg\n",
    "        else:\n",
    "            return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dim = 70\n",
    "class_dim = 1000\n",
    "hyperparams={\n",
    "    'm_neg':0.5,\n",
    "    'm_pos':3.,\n",
    "    'gamma':2.0,\n",
    "    'beta':0.001\n",
    "}\n",
    "network = Network(word_embed, pos_dim, WORD_DIM, RELATION_NUM-1, class_dim, OTHER_LABEL, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def train_func(dataset):\n",
    "    step_count = 0\n",
    "    loss_count = 0\n",
    "    for step, (pos1, pos2, label, words) in enumerate(dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            scores,loss = network([pos1, pos2, label, words], training=True)\n",
    "        grads = tape.gradient(loss, network.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "        loss_count += loss\n",
    "        step_count += 1\n",
    "    loss_avg = loss_count / step_count\n",
    "    return loss_avg\n",
    "\n",
    "def test_func(dataset):\n",
    "    step_count = 0\n",
    "    pred_all = []\n",
    "    label_all = []\n",
    "    correct = 0\n",
    "    for step, (pos1, pos2, label, words) in enumerate(dataset):\n",
    "        scores = network([pos1, pos2, label, words], training=False)\n",
    "        pred = []\n",
    "        for item in scores:\n",
    "            if tf.reduce_max(item) < 0:\n",
    "                pred.append(OTHER_LABEL)\n",
    "            else:\n",
    "                pred.append(tf.argmax(item).numpy())\n",
    "        label_all.extend(list(label.numpy()))\n",
    "        pred_all.extend(pred)\n",
    "    for p, t in zip(pred_all, label_all):\n",
    "        if p == t:\n",
    "            correct += 1\n",
    "            \n",
    "    accuracy = correct / len(label_all)\n",
    "    return accuracy, pred_all, label_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-79-389a19842537>:49 class_loss_func  *\n        first_term = tf.math.log(1.0 + tf.exp(gamma*(m_pos - tf.gather_nd(score, tf.expand_dims(class_label, axis=1), batch_dims=1 ))))\n    /home/runqi/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:899 binary_op_wrapper\n        return func(x, y, name=name)\n    /home/runqi/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py:11088 sub\n        \"Sub\", x=x, y=y, name=name)\n    /home/runqi/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:563 _apply_op_helper\n        inferred_from[input_arg.type_attr]))\n\n    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int32 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-c25bd0316b5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./saved/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-3f9342f688fd>\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-389a19842537>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mclass_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mloss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mother_loss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mloss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_loss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mtheta_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos1_embed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos2_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-79-389a19842537>:49 class_loss_func  *\n        first_term = tf.math.log(1.0 + tf.exp(gamma*(m_pos - tf.gather_nd(score, tf.expand_dims(class_label, axis=1), batch_dims=1 ))))\n    /home/runqi/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:899 binary_op_wrapper\n        return func(x, y, name=name)\n    /home/runqi/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py:11088 sub\n        \"Sub\", x=x, y=y, name=name)\n    /home/runqi/.conda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:563 _apply_op_helper\n        inferred_from[input_arg.type_attr]))\n\n    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int32 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "save_dir = './saved/'\n",
    "for epoch in range(10):\n",
    "    loss_avg = train_func(train_ds)\n",
    "    train_accuracy, pred_all, label_all = test_func(train_ds)\n",
    "    test_accuracy, pred_all, label_all = test_func(test_ds)\n",
    "    if test_accuracy > best_acc:\n",
    "        network.save_weights(save_dir + 'bestckpt')\n",
    "        best_acc = test_accuracy\n",
    "    print('training loss is {0: .4f}, training accuracy is {1: .4f}, test accuracy is {2: .4f}'.format(loss_avg, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7615016562384983\n"
     ]
    }
   ],
   "source": [
    "network.load_weights(save_dir + 'bestckpt')\n",
    "accuracy, pred_all, label_all = test_func(test_ds)\n",
    "label_all = [item[0] for item in label_all]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "id2rel = pickle.load(open(base_dir + 'lb2rel.dict', 'rb'))\n",
    "unique_relations = pickle.load(open(base_dir + 'unique_relations', 'rb'))\n",
    "label_all = [id2rel[item] for item in label_all]\n",
    "pred_all = [id2rel[item] for item in pred_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Entity-Destination       0.84      0.89      0.87       292\n",
      "     Entity-Origin       0.81      0.85      0.83       258\n",
      " Content-Container       0.75      0.90      0.82       192\n",
      "     Message-Topic       0.80      0.85      0.83       261\n",
      "  Product-Producer       0.78      0.69      0.73       231\n",
      " Member-Collection       0.80      0.89      0.84       233\n",
      "      Cause-Effect       0.89      0.92      0.90       328\n",
      " Instrument-Agency       0.77      0.54      0.64       156\n",
      "   Component-Whole       0.85      0.79      0.82       312\n",
      "\n",
      "         micro avg       0.82      0.83      0.82      2263\n",
      "         macro avg       0.81      0.81      0.81      2263\n",
      "      weighted avg       0.82      0.83      0.82      2263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_all, pred_all, labels = [item for item in unique_relations if item !='Other']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
